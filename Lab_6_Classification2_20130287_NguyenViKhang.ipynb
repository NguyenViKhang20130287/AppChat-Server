{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lDy8k60P45gEAki20MPy_7YK7_E_h5U5",
      "authorship_tag": "ABX9TyP4xNU32dcIFBYm7RdB7t7E"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GEJ-2kKEiEjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "565b1dc5-a8f3-41c1-a1c4-c66b509f5a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import libary\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_pipeline(steps, x_train, y_train, x_test, y_test, memory=None, verbose=False):\n",
        "    pl = Pipeline(steps=steps, memory=memory, verbose=verbose)\n",
        "    pl.fit(x_train, y_train)\n",
        "    y_pred = pl.predict(x_test)\n",
        "    accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
        "    precision = round(precision_score(y_test, y_pred, average='macro'), 2)\n",
        "    recall = round(recall_score(y_test, y_pred, average='macro'), 2)\n",
        "    f1 = round(f1_score(y_test, y_pred, average='macro'), 2)\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "ft5S7z_Wt5cV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_with_pipeline_classifier(pl, x_train, y_train, x_test, y_test, param_grid, average='macro',\n",
        "                                       scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs',\n",
        "                                       error_score=np.nan, return_train_score=False):\n",
        "  grid_search = GridSearchCV(estimator=pl, param_grid=param_grid, scoring=scoring,\n",
        "                             n_jobs=n_jobs, refit=refit, cv=cv, verbose=verbose,\n",
        "                             pre_dispatch=pre_dispatch, error_score=error_score,return_train_score=return_train_score)\n",
        "  grid_search.fit(x_train, y_train)\n",
        "  y_pred = grid_search.predict(x_test)\n",
        "  accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
        "  precision = round(precision_score(y_test, y_pred, average=average), 2)\n",
        "  recall = round(recall_score(y_test, y_pred, average=average), 2)\n",
        "  f1 = round(f1_score(y_test, y_pred, average=average), 2)\n",
        "  return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "2yykFm2YCP5z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grids = {\n",
        "    'RandomForest': {\n",
        "        'pca__n_components': [2, 3],\n",
        "        'classifier__n_estimators': [25, 50, 100, 150],\n",
        "        'classifier__max_features': ['sqrt', 'log2', None],\n",
        "        'classifier__max_depth': [3, 6, 9],\n",
        "        'classifier__max_leaf_nodes': [3, 6, 9]\n",
        "    },\n",
        "    'LogisticRegression': {\n",
        "        'pca__n_components': [2, 3],\n",
        "        'classifier__C': [0.01, 0.1, 1, 10],\n",
        "        'classifier__solver': ['liblinear']\n",
        "    },\n",
        "    'KNN': {\n",
        "        'pca__n_components': [2, 3],\n",
        "        'classifier__n_neighbors': [3, 5, 7, 10],\n",
        "        'classifier__weights': ['uniform', 'distance'],\n",
        "        'classifier__metric': ['euclidean', 'manhattan']\n",
        "    },\n",
        "    'SVM': {\n",
        "        'pca__n_components': [2, 3],\n",
        "        'classifier__C': [0.01, 0.1, 1, 10],\n",
        "        'classifier__kernel': ['linear', 'rbf', 'poly'],\n",
        "        'classifier__gamma': ['scale', 'auto']\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "0bG4_Hl6WY_T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'RandomForest': Pipeline([\n",
        "        ('scl', StandardScaler(with_mean=False)),\n",
        "        ('pca', PCA(n_components=3)),\n",
        "        ('classifier', RandomForestClassifier(random_state=42))\n",
        "    ]),\n",
        "\n",
        "    'LogisticRegression': Pipeline([\n",
        "        ('scl', StandardScaler(with_mean=False)),\n",
        "        ('pca', PCA(n_components=3)),\n",
        "        ('classifier', LogisticRegression(max_iter=5000, random_state=42))\n",
        "    ]),\n",
        "\n",
        "    'SVM': Pipeline([\n",
        "        ('scl', StandardScaler(with_mean=False)),\n",
        "        ('pca', PCA(n_components=3)),\n",
        "        ('classifier', SVC(random_state=42))\n",
        "    ]),\n",
        "\n",
        "    'KNN': Pipeline([\n",
        "        ('scl', StandardScaler(with_mean=False)),\n",
        "        ('pca', PCA(n_components=3)),\n",
        "        ('classifier', KNeighborsClassifier())\n",
        "    ])\n",
        "}\n"
      ],
      "metadata": {
        "id": "vy-i7kQAEhXg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1"
      ],
      "metadata": {
        "id": "A7asIkLdlr_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "0nl0zkl0l0IM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***1.1. Apply Pipeline including StandardScaler and PCA(3 principal components) to the iris dataset with the RandomForest classifier as a final estimator.***"
      ],
      "metadata": {
        "id": "5qCQcPwBmDiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [('scl', StandardScaler()),\n",
        "        ('pca', PCA(n_components=3)),\n",
        "        ('clf', RandomForestClassifier(random_state=42))]\n",
        "\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "accuracy, precision, recall, f1 = apply_pipeline(steps, x_train, y_train, x_test, y_test)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jW7ONoVImDCE",
        "outputId": "f35e2311-2858-4bb1-fe2f-fa01a4fd7e7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Precision: 0.95\n",
            "Recall: 0.97\n",
            "F1: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***1.2. Find the best hyperparameters using GridSearchCV for algorithms (Logistic Regression, Random Forest, kNN, SVM) on the preprocessed dataset in the previous step. Then compare the performance of classifiers using accuracy precision, recall, and F1 measures.***"
      ],
      "metadata": {
        "id": "CEea7LeUmF8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in models:\n",
        "  print(f'Model: {model_name}')\n",
        "  accuracy, precision, recall, f1 = fine_tune_with_pipeline_classifier(models[model_name], x_train, y_train, x_test, y_test, param_grids[model_name])\n",
        "  print(f'Accuracy: {accuracy}')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall: {recall}')\n",
        "  print(f'F1: {f1}')\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "eWpOssWcmSoc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "00d5b73d-b1d4-47a1-d073-733f00973f70"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: RandomForest\n",
            "Accuracy: 0.93\n",
            "Precision: 0.92\n",
            "Recall: 0.95\n",
            "F1: 0.92\n",
            "\n",
            "Model: LogisticRegression\n",
            "Accuracy: 0.9\n",
            "Precision: 0.89\n",
            "Recall: 0.92\n",
            "F1: 0.89\n",
            "\n",
            "Model: SVM\n",
            "Accuracy: 0.97\n",
            "Precision: 0.95\n",
            "Recall: 0.97\n",
            "F1: 0.96\n",
            "\n",
            "Model: KNN\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 2"
      ],
      "metadata": {
        "id": "E7MWjoKNK3yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd '/content/drive/MyDrive/Colab Notebooks/ML_2425/Lab 6_Classifier2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KV5McLR_Ll6p",
        "outputId": "94823f12-29f9-469a-da65-105ae0862db1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/ML_2425/Lab 6_Classifier2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_news = pd.read_csv('news.csv')\n",
        "dataset_news.drop_duplicates(keep='first', inplace=True)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def preprosessing(txt):\n",
        "  tokens = word_tokenize(txt)\n",
        "  words = [lemma.lemmatize(token) for token in tokens if\n",
        "token.isalpha() and token not in stop_words]\n",
        "  return ' '.join(words)\n",
        "\n",
        "txt = dataset_news['data'][0]\n",
        "txt2 = preprosessing(txt)\n",
        "\n",
        "dataset_news['data'] = dataset_news['data'].apply(preprosessing)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "dataset_news['labels'] = encoder.fit_transform(dataset_news['labels'])\n",
        "\n",
        "x_train_news, x_test_news, y_train_news, y_test_news = train_test_split(dataset_news['data'], dataset_news['labels'], test_size=0.2, random_state=42)\n",
        "\n",
        "vectorize = TfidfVectorizer()\n",
        "x_train_cv = vectorize.fit_transform(x_train_news)\n",
        "x_test_cv = vectorize.transform(x_test_news)"
      ],
      "metadata": {
        "id": "ssKDt5KHVmd9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***2.1. Apply Pipeline including StandardScaler and RandomForest(select features based on ‘mean’ threshold) to the above dataset with the RandomForest classifier as an estimator.***"
      ],
      "metadata": {
        "id": "AUwzeswehb84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_news = [\n",
        "    ('scl', StandardScaler(with_mean=False)),\n",
        "    ('feature, selection', SelectFromModel(RandomForestClassifier(n_estimators=100))),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "    ]\n",
        "\n",
        "accuracy, precision, recall, f1 = apply_pipeline(steps_news, x_train_cv, y_train_news, x_test_cv, y_test_news)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "k7_Ixqbthhd8",
        "outputId": "10287529-28fb-4c16-f4c8-c26b32f7f708"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n",
            "Precision: 0.98\n",
            "Recall: 0.98\n",
            "F1: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***2.2. Find the best hyperparameters using GridSearchCV for algorithms (Logistic Regression, Random Forest, kNN, SVM)on the preprocessed dataset in the previous steps. Then compare the results using accuracy, precision, recall, and F1 measures.***"
      ],
      "metadata": {
        "id": "fXJWDFB0kaxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, pipeline in models.items():\n",
        "  print(f'Model: {model_name}')\n",
        "  accuracy, precision, recall, f1 = fine_tune_with_pipeline_classifier(pipeline, x_train_cv, y_train_news, x_test_cv, y_test_news, param_grids[model_name], error_score='raise')\n",
        "  print(f'Accuracy: {accuracy}')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall: {recall}')\n",
        "  print(f'F1: {f1}')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QhscngFvkhoe",
        "outputId": "d623f60c-19f4-4bed-e086-6c3c4e257a42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: RandomForest\n",
            "Accuracy: 0.55\n",
            "Precision: 0.56\n",
            "Recall: 0.54\n",
            "F1: 0.54\n",
            "\n",
            "Model: LogisticRegression\n",
            "Accuracy: 0.57\n",
            "Precision: 0.56\n",
            "Recall: 0.55\n",
            "F1: 0.52\n",
            "\n",
            "Model: SVM\n",
            "Accuracy: 0.6\n",
            "Precision: 0.59\n",
            "Recall: 0.59\n",
            "F1: 0.58\n",
            "\n",
            "Model: KNN\n",
            "Accuracy: 0.6\n",
            "Precision: 0.61\n",
            "Recall: 0.6\n",
            "F1: 0.59\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 3"
      ],
      "metadata": {
        "id": "xvF_c5eNncz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_bank = pd.read_csv('bank.csv')"
      ],
      "metadata": {
        "id": "qdRCk55KoIhE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***3.1. Apply Pipeline to StandardScaler() function to columns that contain numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous'); apply Encode Categorical Value (OneHotEncoder) to transform categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome');***"
      ],
      "metadata": {
        "id": "-0VHE4l8nf0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numrical_features = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
        "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']"
      ],
      "metadata": {
        "id": "2D374DKw01Hw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_pipeline = Pipeline([\n",
        "    ('scl', StandardScaler())\n",
        "])\n",
        "cat_pipeline = Pipeline([\n",
        "    ('ohe', OneHotEncoder())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipeline, numrical_features),\n",
        "    ('cat', cat_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "x = dataset_bank.drop('deposit', axis=1)\n",
        "y = dataset_bank['deposit']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "x_train_processed = pipeline.fit_transform(x_train)\n",
        "x_test_processed = pipeline.transform(x_test)\n",
        "\n",
        "x_preprocessed = preprocessor.fit_transform(x)\n",
        "print(x_train_processed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bBk-FOIa1bvL",
        "outputId": "17fb5d67-472e-4657-eb23-0444b42f33ed"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8929, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***3.2. Apply a selection feature technique on the dataset preprocessed in Task 3.1***"
      ],
      "metadata": {
        "id": "_JwLwlCBePsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_bank = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_bank.fit(x_train_processed, y_train)\n",
        "\n",
        "selector_bank = SelectFromModel(rf_bank)\n",
        "x_train_selected = selector_bank.fit_transform(x_train_processed, y_train)\n",
        "x_test_selected = selector_bank.transform(x_test_processed)\n",
        "\n",
        "print(f'Số lượng đặc trưng đã chọn: {x_train_selected.shape[1]}')\n",
        "\n",
        "selected_columns = selector_bank.get_support(indices=True)\n",
        "selected_features = (preprocessor.transformers_[0][1].get_feature_names_out(numrical_features).tolist() +\n",
        "                     preprocessor.transformers_[1][1].named_steps['ohe'].get_feature_names_out(categorical_features).tolist())\n",
        "\n",
        "selected_features = [selected_features[i] for i in selected_columns]\n",
        "\n",
        "print(\"Các đặc trưng đã chọn:\", selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bwBS5LnleRkz",
        "outputId": "56749d79-7908-45d8-becc-3872bc5ea8ab"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng đặc trưng đã chọn: 9\n",
            "Các đặc trưng đã chọn: ['age', 'balance', 'day', 'campaign', 'pdays', 'previous', 'contact_cellular', 'contact_unknown', 'poutcome_success']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***3.3. Then, compare the performance of classification algorithms (Logistic Regression Random forest, kNN, SVM) using accuracy, precision recall, and F1 measures.***"
      ],
      "metadata": {
        "id": "72cvcSJOk_uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_bank = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'SVM': SVC(random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "  print(f'Model: {name}')\n",
        "  model.fit(x_train_selected, y_train)\n",
        "  y_pred = model.predict(x_test_selected)\n",
        "  print(f'Accuracy: {round(accuracy_score(y_test, y_pred), 2)}')\n",
        "  print(f'Precision: {round(precision_score(y_test, y_pred, average=\"macro\"), 2)}')\n",
        "  print(f'Recall: {round(recall_score(y_test, y_pred, average=\"macro\"), 2)}')\n",
        "  print(f'F1: {round(f1_score(y_test, y_pred, average=\"macro\"), 2)}')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lUxMPw1VlGgn",
        "outputId": "80ba6c39-1c81-4617-87ce-d4ecd2f8555e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: RandomForest\n",
            "Accuracy: 0.64\n",
            "Precision: 0.64\n",
            "Recall: 0.64\n",
            "F1: 0.64\n",
            "\n",
            "Model: LogisticRegression\n",
            "Accuracy: 0.63\n",
            "Precision: 0.64\n",
            "Recall: 0.62\n",
            "F1: 0.61\n",
            "\n",
            "Model: SVM\n",
            "Accuracy: 0.66\n",
            "Precision: 0.66\n",
            "Recall: 0.65\n",
            "F1: 0.65\n",
            "\n",
            "Model: KNN\n",
            "Accuracy: 0.63\n",
            "Precision: 0.63\n",
            "Recall: 0.63\n",
            "F1: 0.63\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***3.4. Find the best hyperparameters using GridSearchCV for algorithms (Logistic\n",
        "Regression, Random Forest, kNN, SVM) on the preprocessed dataset in the previous steps.\n",
        "Then compare the results using accuracy, precision, recall, and F1 measures.***"
      ],
      "metadata": {
        "id": "veZ4Y8romqus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, pipeline in models.items():\n",
        "  print(f'Model: {model_name}')\n",
        "  accuracy, precision, recall, f1 = fine_tune_with_pipeline_classifier(pipeline, x_train_selected, y_train, x_test_selected, y_test, param_grids[model_name])\n",
        "  print(f'Accuracy: {accuracy}')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall: {recall}')\n",
        "  print(f'F1: {f1}')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Cf3cf1eAmyt-",
        "outputId": "607d6696-58ce-4308-fd32-189cc5b00fd3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: RandomForest\n",
            "Accuracy: 0.65\n",
            "Precision: 0.66\n",
            "Recall: 0.66\n",
            "F1: 0.65\n",
            "\n",
            "Model: LogisticRegression\n",
            "Accuracy: 0.63\n",
            "Precision: 0.64\n",
            "Recall: 0.62\n",
            "F1: 0.61\n",
            "\n",
            "Model: SVM\n",
            "Accuracy: 0.66\n",
            "Precision: 0.66\n",
            "Recall: 0.65\n",
            "F1: 0.65\n",
            "\n",
            "Model: KNN\n",
            "Accuracy: 0.64\n",
            "Precision: 0.64\n",
            "Recall: 0.63\n",
            "F1: 0.62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***3.5. Plot ROC curve and report the AUC values for classification results on the test set in the\n",
        "previous task.***"
      ],
      "metadata": {
        "id": "vhvDH9tWuAOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "auc_scores = {}"
      ],
      "metadata": {
        "id": "_pYd3WsMuCup"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}